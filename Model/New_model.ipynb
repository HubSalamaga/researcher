{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hubert\\AppData\\Roaming\\Python\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import BertTokenizer, BertModel, AdamW\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from scipy.stats import expon, loguniform, uniform\n",
    "import os\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>AwT score</th>\n",
       "      <th>SoE score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nutritional status and gene polymorphisms of o...</td>\n",
       "      <td>0.168196</td>\n",
       "      <td>0.655265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thrombophilic gene polymorphism is known to be...</td>\n",
       "      <td>0.290110</td>\n",
       "      <td>0.833650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Background Whether adiponectin (ADIPOQ) polymo...</td>\n",
       "      <td>0.600797</td>\n",
       "      <td>0.998080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Polycystic ovary syndrome (PCOS) is a common, ...</td>\n",
       "      <td>0.007601</td>\n",
       "      <td>0.353349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Objective: Endometriosis has been considered a...</td>\n",
       "      <td>0.796838</td>\n",
       "      <td>0.387923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Objective To present the development of the fi...</td>\n",
       "      <td>0.799622</td>\n",
       "      <td>0.171896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Introduction: The aim of the study was to eval...</td>\n",
       "      <td>0.291656</td>\n",
       "      <td>0.826943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Background: Although the precise pathophysiolo...</td>\n",
       "      <td>0.917148</td>\n",
       "      <td>0.667350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Background Key reactions in folate-mediated si...</td>\n",
       "      <td>0.949507</td>\n",
       "      <td>0.873968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Epidemiological studies have suggested that th...</td>\n",
       "      <td>0.090838</td>\n",
       "      <td>0.012471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Aim To investigate association of factor V Lei...</td>\n",
       "      <td>0.287388</td>\n",
       "      <td>0.099722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Objective: The etiology of polycystic ovarian ...</td>\n",
       "      <td>0.758132</td>\n",
       "      <td>0.012246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Kallmann’s syndrome (KS) is characterized by t...</td>\n",
       "      <td>0.963557</td>\n",
       "      <td>0.276913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>We sought to verify whether variation in the p...</td>\n",
       "      <td>0.737175</td>\n",
       "      <td>0.821299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Context: Prior studies showed that Axl /Tyro3 ...</td>\n",
       "      <td>0.831973</td>\n",
       "      <td>0.393188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  AwT score  SoE score\n",
       "0   Nutritional status and gene polymorphisms of o...   0.168196   0.655265\n",
       "1   Thrombophilic gene polymorphism is known to be...   0.290110   0.833650\n",
       "2   Background Whether adiponectin (ADIPOQ) polymo...   0.600797   0.998080\n",
       "3   Polycystic ovary syndrome (PCOS) is a common, ...   0.007601   0.353349\n",
       "4   Objective: Endometriosis has been considered a...   0.796838   0.387923\n",
       "5   Objective To present the development of the fi...   0.799622   0.171896\n",
       "6   Introduction: The aim of the study was to eval...   0.291656   0.826943\n",
       "7   Background: Although the precise pathophysiolo...   0.917148   0.667350\n",
       "8   Background Key reactions in folate-mediated si...   0.949507   0.873968\n",
       "9   Epidemiological studies have suggested that th...   0.090838   0.012471\n",
       "10  Aim To investigate association of factor V Lei...   0.287388   0.099722\n",
       "11  Objective: The etiology of polycystic ovarian ...   0.758132   0.012246\n",
       "12  Kallmann’s syndrome (KS) is characterized by t...   0.963557   0.276913\n",
       "13  We sought to verify whether variation in the p...   0.737175   0.821299\n",
       "14  Context: Prior studies showed that Axl /Tyro3 ...   0.831973   0.393188"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data_from_csv(file_path):\n",
    "    dataframe = pd.read_csv(file_path)\n",
    "    return dataframe\n",
    "\n",
    "cwd = os.getcwd()\n",
    "file_path = os.path.join(cwd, r\"data\\initial_training_data\\test.csv\")\n",
    "dataset = load_data_from_csv(file_path)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomize_scores(scores, max_deviation= 0.05):\n",
    "    randomized_scores = scores * (1 + np.random.uniform(-max_deviation,max_deviation,size=scores.shape))\n",
    "    return np.clip(randomized_scores,0,1)\n",
    "\n",
    "train_y = dataset[['AwT score', 'SoE score']].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def penalty_function_AwT(AwT, alpha=2, epsilon=1e-6):\n",
    "#     return torch.exp(-(AwT + epsilon)**alpha)\n",
    "\n",
    "# def reward_function_AwT(AwT, beta=2):\n",
    "#     return (torch.exp(AwT - 0.5))**beta\n",
    "\n",
    "# def penalty_function_SoE(SoE, gamma=2, epsilon=1e-6):\n",
    "#     return torch.exp(-(SoE + epsilon)**gamma)\n",
    "\n",
    "# def reward_function_SoE(SoE, delta=2):\n",
    "#     return (torch.exp(SoE - 0.5))**delta\n",
    "\n",
    "# def calculate_final_score(SoE, AwT, w_SoE=0.4, w_AwT=0.6, alpha=2, beta=2, gamma=2, delta=2):\n",
    "#     base_score = w_SoE * SoE + w_AwT * AwT\n",
    "\n",
    "#     AwT_score = torch.where(AwT < 0.5, base_score * penalty_function_AwT(AwT, alpha), base_score * reward_function_AwT(AwT, beta))\n",
    "#     final_score = torch.where(SoE < 0.5, AwT_score * penalty_function_SoE(SoE, gamma), AwT_score * reward_function_SoE(SoE, delta))\n",
    "    \n",
    "#     return final_score\n",
    "\n",
    "# def custom_scorer(y_true, y_pred):\n",
    "#     scores = []\n",
    "#     for true, pred in zip(y_true, y_pred):\n",
    "#         score = calculate_final_score(true[1], true[0])  # Assuming y_true contains [AwT, SoE]\n",
    "#         scores.append(score)\n",
    "#     return mean_squared_error(y_true, scores)\n",
    "\n",
    "# def evaluate_hyperparameters(alpha, beta, gamma, delta):\n",
    "#     def model_evaluation(SoE, AwT):\n",
    "#         return calculate_final_score(SoE, AwT, alpha=alpha, beta=beta, gamma=gamma, delta=delta)\n",
    "#     return model_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hubert\\anaconda3\\envs\\bs4\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Hubert\\anaconda3\\envs\\bs4\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Hubert\\anaconda3\\envs\\bs4\\Lib\\site-packages\\transformers\\optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.30456966161727905\n",
      "Epoch 2, Loss: 0.12368088215589523\n",
      "Epoch 3, Loss: 0.08395057171583176\n",
      "Epoch 4, Loss: 0.09876461327075958\n",
      "Epoch 1, Loss: 0.5026987195014954\n",
      "Epoch 2, Loss: 0.18994569778442383\n",
      "Epoch 3, Loss: 0.09096721559762955\n",
      "Epoch 4, Loss: 0.067817322909832\n"
     ]
    }
   ],
   "source": [
    "# Load your dataset\n",
    "# dataset = pd.read_csv(\"path_to_your_dataset.csv\")\n",
    "# Assuming 'text' column contains abstracts and 'score' column contains labels\n",
    "\n",
    "# def custom_loss(predictions, targets, w_SoE=0.4, w_AwT=0.6, alpha=2, beta=2, gamma=2, delta=2):\n",
    "#     mse_loss = F.mse_loss(predictions, targets)\n",
    "    \n",
    "#     AwT = targets[:, 0]\n",
    "#     SoE = targets[:, 1]\n",
    "#     final_scores = calculate_final_score(SoE, AwT, w_SoE, w_AwT, alpha, beta, gamma, delta)\n",
    "    \n",
    "#     reward_punishment_term = torch.tensor(final_scores, dtype=torch.float32, device=predictions.device)\n",
    "    \n",
    "#     # Integrate the reward/punishment term with the MSE loss\n",
    "#     total_loss = mse_loss - reward_punishment_term.mean()\n",
    "    \n",
    "#     return total_loss\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "scores_to_randomize = dataset[[\"AwT score\", \"SoE score\"]].values\n",
    "randomized_scores = randomize_scores(scores_to_randomize)\n",
    "dataset[[\"AwT score\", \"SoE score\"]] = randomized_scores\n",
    "train_data, test_data = train_test_split(dataset, test_size=0.4, random_state=42)\n",
    "\n",
    "# Initializing tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\")\n",
    "\n",
    "# Function to prepare DataLoader\n",
    "def prepare_dataloader(data, batch_size=6, test=False):\n",
    "    inputs = tokenizer(data[\"text\"].tolist(), padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "    labels = torch.tensor(data[[\"AwT score\", \"SoE score\"]].values).float()\n",
    "    dataset = TensorDataset(inputs['input_ids'], inputs['attention_mask'], labels)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=not test)\n",
    "    return dataloader\n",
    "\n",
    "train_dataloader = prepare_dataloader(train_data,batch_size=15)\n",
    "test_dataloader = prepare_dataloader(test_data, batch_size=15, test=True)\n",
    "\n",
    "class BertForRegression(nn.Module):\n",
    "    def __init__(self, model_name, hidden_size=768):\n",
    "        super(BertForRegression, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(model_name)\n",
    "        self.regressor = nn.Linear(hidden_size, 2)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids=None, return_embeddings=False):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        if return_embeddings:\n",
    "            return pooled_output\n",
    "        return self.regressor(pooled_output)\n",
    "    \n",
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)\n",
    "\n",
    "def train_model(train_dataloader, device, epochs = 4, model_index = 0):\n",
    "    model = BertForRegression(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\")\n",
    "    model.to(device)\n",
    "    optimizer = AdamW(model.parameters(), lr=2e-5) # test value  # torch.optim.AdamW\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch in train_dataloader:\n",
    "            b_input_ids, b_input_mask, b_labels = [item.to(device) for item in batch] #co to jest b_input_ids\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(b_input_ids,b_input_mask) #co to jest????\n",
    "            #loss = criterion(outputs.squeeze(),b_labels)\n",
    "            loss = criterion(outputs,b_labels)  # Use the custom loss function #outputs = predictions , b_labels = targets \n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {avg_train_loss}\")\n",
    "        save_model(model, f\"trained_model_{model_index}.pt\")\n",
    "    \n",
    "    model_index += 1\n",
    "    return model\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_models = 2\n",
    "models = [train_model(train_dataloader, device) for _ in range(num_models)]\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_models(models, test_dataloader, device):\n",
    "    all_predictions = []\n",
    "    true_scores = []\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "        predictions = []\n",
    "        with torch.no_grad():\n",
    "            for batch in test_dataloader:\n",
    "                b_input_ids, b_input_mask, b_labels = [item.to(device) for item in batch]\n",
    "                outputs = model(b_input_ids, b_input_mask)\n",
    "                predictions.extend(outputs.cpu().numpy())\n",
    "                true_scores.extend(b_labels.cpu().numpy())\n",
    "        all_predictions.append(predictions)\n",
    "\n",
    "    avg_predictions = np.mean(all_predictions, axis=0)\n",
    "    true_scores = np.array(true_scores)\n",
    "    return avg_predictions, all_predictions, true_scores\n",
    "\n",
    "\n",
    "avg_predictions, all_predictions, true_scores = evaluate_models(models, test_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "avg_predictions, all_predictions, true_scores = evaluate_models(models, test_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    AwT score  SoE score\n",
      "0    0.164669   0.653455\n",
      "5    0.832329   0.170398\n",
      "8    0.952668   0.865815\n",
      "9    0.093548   0.011887\n",
      "11   0.787713   0.012763\n",
      "13   0.756239   0.814158\n",
      "Shape of avg_predictions: (6, 2)\n",
      "Shape of true_scores: (6, 2)\n",
      "Average MSE: AwT score    0.119787\n",
      "SoE score    0.178199\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Assuming true_scores is already defined correctly\n",
    "true_scores = dataset.drop(test_data.index)\n",
    "train_scores_true = dataset.drop(true_scores.index)\n",
    "train_scores_true = train_scores_true.iloc[:,1:3]\n",
    "print(train_scores_true)\n",
    "#Check the shape of avg_predictions\n",
    "print(f\"Shape of avg_predictions: {avg_predictions.shape}\")\n",
    "print(f\"Shape of true_scores: {train_scores_true.shape}\")\n",
    "\n",
    "mse = ((avg_predictions - train_scores_true) ** 2).mean(axis=0)\n",
    "print(f\"Average MSE: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 text  AwT score  SoE score\n",
      "9   Epidemiological studies have suggested that th...   0.093548   0.011887\n",
      "11  Objective: The etiology of polycystic ovarian ...   0.787713   0.012763\n",
      "0   Nutritional status and gene polymorphisms of o...   0.164669   0.653455\n",
      "13  We sought to verify whether variation in the p...   0.756239   0.814158\n",
      "5   Objective To present the development of the fi...   0.832329   0.170398\n",
      "8   Background Key reactions in folate-mediated si...   0.952668   0.865815\n",
      "[[0.6885146  0.593044  ]\n",
      " [0.7148416  0.7222628 ]\n",
      " [0.6353173  0.6019128 ]\n",
      " [0.65444356 0.619995  ]\n",
      " [0.67150545 0.575848  ]\n",
      " [0.715201   0.7471938 ]]\n"
     ]
    }
   ],
   "source": [
    "#test_data\n",
    "print(test_data)\n",
    "print(avg_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bs4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
