{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import BertTokenizer, BertModel, AdamW\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from scipy.stats import expon, loguniform, uniform\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>AwT score</th>\n",
       "      <th>SoE score</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nutritional status and gene polymorphisms of o...</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.20</td>\n",
       "      <td>PMC9569987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thrombophilic gene polymorphism is known to be...</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.50</td>\n",
       "      <td>PMC6045916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Background Whether adiponectin (ADIPOQ) polymo...</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.00</td>\n",
       "      <td>PMC6278103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Polycystic ovary syndrome (PCOS) is a common, ...</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.00</td>\n",
       "      <td>PMC4557132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Objective: Endometriosis has been considered a...</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.55</td>\n",
       "      <td>21429654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Objective To present the development of the fi...</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.55</td>\n",
       "      <td>PMC7169920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Introduction: The aim of the study was to eval...</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.60</td>\n",
       "      <td>28819944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Background: Although the precise pathophysiolo...</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.00</td>\n",
       "      <td>18277167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Background Key reactions in folate-mediated si...</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.40</td>\n",
       "      <td>PMC8792379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Epidemiological studies have suggested that th...</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.60</td>\n",
       "      <td>PMID: 25102261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Aim To investigate association of factor V Lei...</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.55</td>\n",
       "      <td>PMID: 29703881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Objective: The etiology of polycystic ovarian ...</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.00</td>\n",
       "      <td>31122534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Kallmann’s syndrome (KS) is characterized by t...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.40</td>\n",
       "      <td>12050219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>We sought to verify whether variation in the p...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.55</td>\n",
       "      <td>17339269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Context: Prior studies showed that Axl /Tyro3 ...</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.50</td>\n",
       "      <td>PMC3973777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text   AwT score   SoE score  \\\n",
       "0   Nutritional status and gene polymorphisms of o...        0.90        0.20   \n",
       "1   Thrombophilic gene polymorphism is known to be...        0.90        0.50   \n",
       "2   Background Whether adiponectin (ADIPOQ) polymo...        0.95        1.00   \n",
       "3   Polycystic ovary syndrome (PCOS) is a common, ...        0.95        1.00   \n",
       "4   Objective: Endometriosis has been considered a...        0.95        0.55   \n",
       "5   Objective To present the development of the fi...        0.95        0.55   \n",
       "6   Introduction: The aim of the study was to eval...        0.95        0.60   \n",
       "7   Background: Although the precise pathophysiolo...        0.95        1.00   \n",
       "8   Background Key reactions in folate-mediated si...        0.95        0.40   \n",
       "9   Epidemiological studies have suggested that th...        0.95        0.60   \n",
       "10  Aim To investigate association of factor V Lei...        0.95        0.55   \n",
       "11  Objective: The etiology of polycystic ovarian ...        0.95        1.00   \n",
       "12  Kallmann’s syndrome (KS) is characterized by t...        0.75        0.40   \n",
       "13  We sought to verify whether variation in the p...        0.75        0.55   \n",
       "14  Context: Prior studies showed that Axl /Tyro3 ...        0.85        0.50   \n",
       "\n",
       "                 ID  \n",
       "0        PMC9569987  \n",
       "1        PMC6045916  \n",
       "2        PMC6278103  \n",
       "3        PMC4557132  \n",
       "4          21429654  \n",
       "5        PMC7169920  \n",
       "6          28819944  \n",
       "7          18277167  \n",
       "8        PMC8792379  \n",
       "9    PMID: 25102261  \n",
       "10   PMID: 29703881  \n",
       "11         31122534  \n",
       "12         12050219  \n",
       "13         17339269  \n",
       "14       PMC3973777  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data_from_csv(file_path):\n",
    "    dataframe = pd.read_csv(file_path)\n",
    "    return dataframe\n",
    "\n",
    "cwd = os.getcwd()\n",
    "file_path = r\"C:\\Users\\Hubert\\Documents\\GitHub\\researcher\\Model\\data\\initial_training_data\\new_data.csv\"\n",
    "dataset = load_data_from_csv(file_path)\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomize_scores(scores, max_deviation= 0.05):\n",
    "    randomize_scores = scores * (1 + np.random.uniform(-max_deviation,max_deviation,size=scores.shape))\n",
    "    return np.clip(randomize_scores,0,1)\n",
    "\n",
    "train_x = dataset[\"text\"].tolist()\n",
    "train_y = dataset[[\" AwT score\", \" SoE score\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#This will be a separate module\n",
    "def penalty_function_AwT(AwT, alpha = 1, epsilon = 1e-6):\n",
    "    if AwT < 0.5:\n",
    "        return 1 / (AwT+epsilon)**alpha\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def reward_function_AwT(AwT, beta = 1):\n",
    "    if AwT > 0.5:\n",
    "        return (np.exp(AwT - 0.5))**beta\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def penalty_function_SoE(SoE, gamma=0.5, epsilon=1e-6):\n",
    "    if SoE < 0.5:\n",
    "        return 1 / (SoE + epsilon)**gamma\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def reward_function_SoE(SoE, delta=0.5):\n",
    "    if SoE > 0.5:\n",
    "        return (np.exp(SoE - 0.5))**delta\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def calculate_final_score(SoE, AwT, w_SoE=0.4, w_AwT=0.6, alpha=1, beta=1, gamma=0.5, delta=0.5):\n",
    "    base_score = w_SoE * SoE + w_AwT * AwT\n",
    "    \n",
    "    if AwT < 0.5:\n",
    "        AwT_score = base_score * penalty_function_AwT(AwT, alpha)\n",
    "    else:\n",
    "        AwT_score = base_score * reward_function_AwT(AwT, beta)\n",
    "    \n",
    "    if SoE < 0.5:\n",
    "        final_score = AwT_score * penalty_function_SoE(SoE, gamma)\n",
    "    else:\n",
    "        final_score = AwT_score * reward_function_SoE(SoE, delta)\n",
    "    \n",
    "    return final_score\n",
    "\n",
    "def custom_scorer(y_true, y_pred):\n",
    "    return mean_squared_error(y_true, y_pred)\n",
    "\n",
    "def evaluate_hyperparameters(alpha, beta, gamma, delta):\n",
    "    def model_evaluation(SoE, AwT):\n",
    "        return calculate_final_score(SoE, AwT, alpha=alpha, beta=beta, gamma=gamma, delta=delta)\n",
    "    return model_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hubert\\anaconda3\\envs\\bs4\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Hubert\\anaconda3\\envs\\bs4\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Hubert\\anaconda3\\envs\\bs4\\Lib\\site-packages\\transformers\\optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.45474890371163684\n",
      "Epoch 2, Loss: 0.05409636224309603\n",
      "Epoch 3, Loss: 0.06230992699662844\n",
      "Epoch 4, Loss: 0.030206528181831043\n",
      "Epoch 5, Loss: 0.021787068496147793\n",
      "Epoch 6, Loss: 0.03203940391540527\n",
      "Epoch 7, Loss: 0.014882573547462622\n",
      "Epoch 8, Loss: 0.014358392916619778\n",
      "Epoch 1, Loss: 0.42231058577696484\n",
      "Epoch 2, Loss: 0.06120533992846807\n",
      "Epoch 3, Loss: 0.06397892472644646\n",
      "Epoch 4, Loss: 0.029366400713721912\n",
      "Epoch 5, Loss: 0.029692060003678005\n",
      "Epoch 6, Loss: 0.02911361896743377\n",
      "Epoch 7, Loss: 0.022550317148367565\n",
      "Epoch 8, Loss: 0.013491117085019747\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['AwT score', 'SoE score'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 84\u001b[0m\n\u001b[0;32m     81\u001b[0m test_dataloader \u001b[38;5;241m=\u001b[39m prepare_dataloader(dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# Use your actual test data here\u001b[39;00m\n\u001b[0;32m     83\u001b[0m avg_predictions \u001b[38;5;241m=\u001b[39m evaluate_models(models, test_dataloader, device)\n\u001b[1;32m---> 84\u001b[0m true_scores \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAwT score\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSoE score\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m     85\u001b[0m mse \u001b[38;5;241m=\u001b[39m ((avg_predictions \u001b[38;5;241m-\u001b[39m true_scores) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage MSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Hubert\\anaconda3\\envs\\bs4\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Hubert\\anaconda3\\envs\\bs4\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Hubert\\anaconda3\\envs\\bs4\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[0;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[1;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['AwT score', 'SoE score'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# Load your dataset\n",
    "# dataset = pd.read_csv(\"path_to_your_dataset.csv\")\n",
    "# Assuming 'text' column contains abstracts and 'score' column contains labels\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "\n",
    "# Initializing tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\")\n",
    "\n",
    "# Function to prepare DataLoader\n",
    "def prepare_dataloader(data, batch_size=6):\n",
    "    inputs = tokenizer(data[\"text\"].tolist(), padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "    labels = torch.tensor(data[[\" AwT score\", \" SoE score\"]].values).float()\n",
    "    dataset = TensorDataset(inputs['input_ids'], inputs['attention_mask'], labels)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    return dataloader\n",
    "\n",
    "train_dataloader = prepare_dataloader(dataset)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class BertForRegression(nn.Module):\n",
    "    def __init__(self, model_name, hidden_size=768):\n",
    "        super(BertForRegression, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(model_name)\n",
    "        self.regressor = nn.Linear(hidden_size, 2)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids=None, return_embeddings=False):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        if return_embeddings:\n",
    "            return pooled_output\n",
    "        return self.regressor(pooled_output)\n",
    "    \n",
    "\n",
    "\n",
    "def train_model(train_dataloader, device, epochs = 8):\n",
    "    model = BertForRegression(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\")\n",
    "    model.to(device)\n",
    "    optimizer = AdamW(model.parameters(), lr=2e-5) # test value  # torch.optim.AdamW\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch in train_dataloader:\n",
    "            b_input_ids, b_input_mask, b_labels = [item.to(device) for item in batch]\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(b_input_ids,b_input_mask)\n",
    "            loss = criterion(outputs.squeeze(),b_labels)\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {avg_train_loss}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "num_models = 2\n",
    "models = [train_model(train_dataloader, device) for _ in range(num_models)]\n",
    "\n",
    "def evaluate_models(models, test_dataloader, device):\n",
    "    all_predictions = []\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "        predictions = []\n",
    "        with torch.no_grad():\n",
    "            for batch in test_dataloader:\n",
    "                b_input_ids, b_input_mask, _ = [item.to(device) for item in batch]\n",
    "                outputs = model(b_input_ids, b_input_mask)\n",
    "                predictions.extend(outputs.squeeze().cpu().numpy())\n",
    "        all_predictions.append(predictions)\n",
    "    \n",
    "    avg_predictions = np.mean(all_predictions, axis=0)\n",
    "    return avg_predictions\n",
    "\n",
    "test_dataloader = prepare_dataloader(dataset, batch_size=1) # Use your actual test data here\n",
    "\n",
    "avg_predictions = evaluate_models(models, test_dataloader, device)\n",
    "true_scores = dataset[[\" AwT score\", \"SoE score\"]].values\n",
    "mse = ((avg_predictions - true_scores) ** 2).mean(axis=0)\n",
    "print(f\"Average MSE: {mse}\")\n",
    "\n",
    "\n",
    "param_distributions = {\n",
    "    'alpha' : [expon(scale=1.0), uniform(0.1,1.9)],\n",
    "    'beta' : [loguniform(1e-3,1e1),uniform(0.1,1.9)],\n",
    "    'gamma' : [expon(scale=1.0),uniform(0.1,1.9)],\n",
    "    'delta' : [uniform(0.1,1.9), expon(scale=1.0)]\n",
    "}\n",
    "\n",
    "random_search=RandomizedSearchCV(\n",
    "    estimator=evaluate_hyperparameters,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=100,\n",
    "    scoring=make_scorer(custom_score, greater_is_better= False),\n",
    "    cv=5,\n",
    "    random_state=42\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9252603  0.77776223 0.96740234 0.68590736 1.0221708  0.77937067\n",
      " 1.0072647  0.7213042  0.9108105  0.8359132  0.8974997  0.66318786\n",
      " 0.99135613 0.8875499  0.9612308  0.44953763 1.0182903  0.69183224\n",
      " 1.0016801  0.57063335 0.9987792  0.78549373 1.0043609  0.83751607\n",
      " 0.81779003 0.69042003 0.9553925  0.7575235  1.0299163  0.6484913 ]\n",
      "[[0.9  0.2 ]\n",
      " [0.9  0.5 ]\n",
      " [0.95 1.  ]\n",
      " [0.95 1.  ]\n",
      " [0.95 0.55]\n",
      " [0.95 0.55]\n",
      " [0.95 0.6 ]\n",
      " [0.95 1.  ]\n",
      " [0.95 0.4 ]\n",
      " [0.95 0.6 ]\n",
      " [0.95 0.55]\n",
      " [0.95 1.  ]\n",
      " [0.75 0.4 ]\n",
      " [0.75 0.55]\n",
      " [0.85 0.5 ]]\n"
     ]
    }
   ],
   "source": [
    "# Example data\n",
    "# X_train, y_train should be your training data\n",
    "# x_train: array of pairs (SoE, AwT)\n",
    "# y_train: corresponding true scores\n",
    "\n",
    "#random_search.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of avg_predictions: (15, 2)\n",
      "Shape of true_scores: (15, 2)\n",
      "Average MSE: [0.0074412  0.08615448]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'evaluate_hyperparameters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 27\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage MSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m param_distributions \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m'\u001b[39m : [expon(scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m), uniform(\u001b[38;5;241m0.1\u001b[39m,\u001b[38;5;241m1.9\u001b[39m)],\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbeta\u001b[39m\u001b[38;5;124m'\u001b[39m : [loguniform(\u001b[38;5;241m1e-3\u001b[39m,\u001b[38;5;241m1e1\u001b[39m),uniform(\u001b[38;5;241m0.1\u001b[39m,\u001b[38;5;241m1.9\u001b[39m)],\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgamma\u001b[39m\u001b[38;5;124m'\u001b[39m : [expon(scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m),uniform(\u001b[38;5;241m0.1\u001b[39m,\u001b[38;5;241m1.9\u001b[39m)],\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdelta\u001b[39m\u001b[38;5;124m'\u001b[39m : [uniform(\u001b[38;5;241m0.1\u001b[39m,\u001b[38;5;241m1.9\u001b[39m), expon(scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)]\n\u001b[0;32m     24\u001b[0m }\n\u001b[0;32m     26\u001b[0m random_search\u001b[38;5;241m=\u001b[39mRandomizedSearchCV(\n\u001b[1;32m---> 27\u001b[0m     estimator\u001b[38;5;241m=\u001b[39m\u001b[43mevaluate_hyperparameters\u001b[49m,\n\u001b[0;32m     28\u001b[0m     param_distributions\u001b[38;5;241m=\u001b[39mparam_distributions,\n\u001b[0;32m     29\u001b[0m     n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m     30\u001b[0m     scoring\u001b[38;5;241m=\u001b[39mmake_scorer(custom_score, greater_is_better\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m     31\u001b[0m     cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m     32\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[0;32m     33\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'evaluate_hyperparameters' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming true_scores is already defined correctly\n",
    "true_scores = dataset[[\" AwT score\", \" SoE score\"]].values\n",
    "\n",
    "# Check the shape of avg_predictions\n",
    "print(f\"Shape of avg_predictions: {avg_predictions.shape}\")\n",
    "print(f\"Shape of true_scores: {true_scores.shape}\")\n",
    "\n",
    "# If avg_predictions is not 2D, reshape it accordingly\n",
    "if avg_predictions.ndim == 1:\n",
    "    avg_predictions = avg_predictions.reshape(-1, 2)\n",
    "\n",
    "# Ensure avg_predictions has the same number of samples as true_scores\n",
    "if avg_predictions.shape[0] != true_scores.shape[0]:\n",
    "    raise ValueError(\"Number of samples in predictions and true scores do not match.\")\n",
    "\n",
    "mse = ((avg_predictions - true_scores) ** 2).mean(axis=0)\n",
    "print(f\"Average MSE: {mse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bs4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
