from Bio import Entrez
import os
import time
import datetime
from bs4 import BeautifulSoup

class Const:
    @staticmethod
    def write_current_date():
        """
        Write current date and creates a file called current_date to store it 
        Runs only once to generate the file which is later modified by overwrite_date (?)

        Returns:
        data_file_path(str): Path to the file containing the date
        current_date(date): Current date in date format by default YYYY-MM-DD
        """
        current_date = datetime.datetime.now().date()
        cwd = os.getcwd()
        dir_path_date = os.path.join(cwd,"date")
        date_file_path = os.path.join(dir_path_date,"current_date.txt")
        if not os.path.exists(dir_path_date): 
            os.makedirs(dir_path_date)
            with open(date_file_path, 'w') as date_file:
                date_file.write(str(current_date))
                return date_file_path, current_date
        else: 
            return date_file_path, current_date
    @staticmethod
    def read_date(date_file_path):
      """
      Read current date from file generated by write_current_date()

      Args:
      data_file_path(str): path to file storing current date

      Returns:
      previous_date(str): The date written out during previous runtime by write_current_date(), same formating as the current_date but as string
      """
      if os.path.exists(date_file_path):
        with open(date_file_path, 'r') as date_file:
            previous_date = date_file.read()
            return previous_date
    @staticmethod
    def user_construct_query_with_numbers(terms_operators_dict):
        """
        Constructs a query string dynamically by allowing the user to choose the order of terms
        and the operators connecting them using numeric identifiers. Users can terminate the
        query creation at any point.

        Parameters:
        - terms_operators_dict (dict): Dictionary with search terms as keys and sets of logical operators as values.

        Returns:
        - str: The user-constructed query string.
        """
        query_parts = []
        operators_list = ['AND', 'OR',
                        'NOT']  # Assuming all terms can use all operators for simplicity we will customize that later i think

        print("Available terms:")
        for i, term in enumerate(terms_operators_dict.keys(), start=1):  # this makes that beautiful list we select from
            print(f"{i}. {term}")

        while True:
            term_index = int(input("Enter the number for your next term (or 0 to finish): ")) - 1
            if term_index == -1:  # rudimentary error resolution
                break

            # Check for valid term selection
            if 0 <= term_index < len(terms_operators_dict):
                term = list(terms_operators_dict.keys())[term_index]
                if query_parts:  # If this is not the first term, ask for an operator
                    print("Choose an operator to connect the terms:")
                    for i, op in enumerate(operators_list, start=1):
                        print(f"{i}. {op}")
                    op_index = int(input()) - 1

                    # Check for valid operator selection and append it to the query
                    if 0 <= op_index < len(operators_list):
                        query_parts.append(operators_list[op_index])
                    else:
                        print("Invalid operator selection. Skipping...")
                query_parts.append(term)
            else:
                print("Invalid term selection. Please try again.")

        return ' '.join(query_parts)
    @staticmethod
    def fetch_pmc_ids(query):
        """
        Fetches PMC IDs from NCBI using a list of keywords.

        Parameters:
        - keywords (list): A list of keywords for the search.

        Returns:
        - pmc_ids(list) : A list of PMC IDs.
        """
        # Provide your email to NCBI
        Entrez.email = "kacper.pietrzyk@stud.umed.lodz.pl"

        # Use Entrez.esearch to search the PMC database for the keywords
        handle = Entrez.esearch(db="pmc", term=query, retmax=50)
        record = Entrez.read(handle)
        handle.close()

        # Extract the list of PMC IDs from the search results
        pmc_ids = record['IdList']

        return pmc_ids
    @staticmethod
    def read_queries_and_fetch_articles(file_path, download_dir,current_date,previous_date):
        """
        Reads queries from a file, fetches PMC IDs for each query, and downloads the articles.

        Parameters:
        - file_path (str): Path to the file containing the queries.
        - download_dir (str): The directory where articles should be saved.
        """
        from_format = "%Y-%m-%d"
        to_format = "%Y/%m/%d"
        current_date = str(current_date)
        previous_date = str(previous_date)
        current_date = Const.convert_date_format(current_date,from_format,to_format)  # Remove any leading/trailing whitespace
        previous_date = Const.convert_date_format(previous_date,from_format,to_format)
        #("2024/04/15"[PubDate] : "2024/04/22"[PubDate])
        with open(file_path, 'r') as file:
            for query in file:
                query = query.strip()
                folder_query = query
                if current_date != previous_date:
                query = str(query + " AND " "(" + previous_date + "[PubDate]" + " :"  + " " + current_date + "[PubDate]" + ")") # jeśli odpalamy po raz pierwszy to co się dzieje 
                folder_name_components = [download_dir, folder_query ] 
                folder_name = "/".join(folder_name_components)
                if not os.path.exists(folder_name):  # Checks whether destination directory hasn't been yet created
                    if query:  # Ensure the query is not empty
                        print(f"Processing query: {query}")
                        destination_dir = os.path.join(download_dir, folder_query)
                        print(f"Creating new folder: {destination_dir}")
                        os.makedirs(destination_dir)
                        Const.download_pmc_articles(query, destination_dir, max_retries=3, rate_limit=0.33)
    @staticmethod
    def download_pmc_articles(query, destination_dir, max_retries=3, rate_limit=0.33):
        """
        Downloads articles from NCBI PMC based on a list of keywords, with rate limiting and retries.

        Parameters:
        - query (str): Initial constructed query
        - destination_dir (str): The directory where articles should be saved.
        - max_retries (int): Maximum number of retries for each request.
        - rate_limit (float): Minimum time delay between requests in seconds.
        """
        # Set your email here
        Entrez.email = 'kacper.pietrzyk@stud.umed.lodz.pl'
        # Fetch PMC IDs
        # Tutaj funkcja modyfikująca query tak aby uwzględniało date 
        # Ta funkcja powinna być odpalona tylko wtedy gdy istnieje już folder zawierający artykuły 
        # Trzeba pomyśleć że skoro później robimy zapytania co jakiś czas to można je odseparować od reszty w folderach 
        pmc_ids = Const.fetch_pmc_ids(query)

        # Iterate over each PMC ID to download the article
        for pmc_id in pmc_ids:
            retries = 0
            success = False
            while retries < max_retries and not success:
                try:
                    # Use Entrez.efetch to fetch the article content
                    handle = Entrez.efetch(db="pmc", id=pmc_id, rettype="xml")
                    article_content = handle.read()
                    handle.close()

                    # Define the path for saving the article
                    article_path = os.path.join(destination_dir, f"{pmc_id}.xml")

                    # Save the article content to a file
                    with open(article_path, 'wb') as article_file:
                        article_file.write(article_content)

                    success = True  # Mark as successful to exit the loop
                except Exception as e:
                    print(f"Error downloading article {pmc_id}: {e}. Retrying...")
                    retries += 1
                    time.sleep(rate_limit)  # Wait before retrying
                finally:
                    if not success:  # Ensure rate limiting even in case of success
                        time.sleep(rate_limit)

        print(f"Downloaded {len(pmc_ids)} articles to {destination_dir}")
    @staticmethod
    def overwrite_date(date_file_path, previous_date, current_date, is_first_run = False, threshold = 7):
        current_date = str(current_date)
        current_date = datetime.datetime.strptime(current_date,"%Y-%m-%d").date()
        previous_date = datetime.datetime.strptime(previous_date,"%Y-%m-%d").date()
        date_difference = abs((current_date - previous_date).days)
        download_dir = ""
        try:
            if is_first_run:
                file_path = "./cos.txt"
                Const.read_queries_and_fetch_articles(file_path, download_dir,current_date,previous_date)
                print(f"First")
            elif date_difference == 0:
                # Handle the case where the program is run on the same day
                print("Program run on the same day")
            elif date_difference >= threshold:
                file_path = "./cos.txt"
                Const.read_queries_and_fetch_articles(file_path, download_dir, current_date, previous_date)
                print(f"More than {threshold} days passed")
            else:
                print(f"Less than {threshold} days passed")
        except Exception as e:
            print(f"An error has occured {e}")
    @staticmethod
    def convert_date_format(date_str, from_format, to_format):
        # Parse the input date string using the from_format
        date_obj = datetime.datetime.strptime(date_str, from_format)
        
        # Format the date object using the to_format
        converted_date_str = date_obj.strftime(to_format)
        
        return converted_date_str
    @staticmethod
    def extract_body_from_html_files(folder_path):
        """Add try catch statements 
        veryfiy paths allow for mulitple inputs"""
        if not os.path.isdir(folder_path):
            raise ValueError("The provided path is not a valid directory")
        
        body_contents = {}
        for filename in os.listdir(folder_path):
            if filename.endswith('.xml'):
                file_path = os.path.join(folder_path,filename)
                with open(file_path,'r',encoding='utf-8') as file:
                    soup = BeautifulSoup(file, 'html.parser')
                    body = soup.find('body')
                    if body:
                        body_path = os.path.join(folder_path,"html_bodies")
                        if not os.path.exists(body_path):
                            os.makedirs(body_path)
                        output_file_path = os.path.join(body_path, f"{os.path.splitext(filename)[0]}_body.html")
                        with open(output_file_path,'w', encoding='utf-8') as output_file:
                            output_file.write(str(body))
                    else:
                        print(f"No body tag found")
        return body_contents
    @staticmethod
    def extract_abstract_from_html_files(*folder_paths):
        """Extracts abstracts from XML files in given folder paths and saves them as HTML files."""
        
        abstract_contents = {}
        
        for folder_path in folder_paths:
            if not os.path.isdir(folder_path):
                print(f"Skipping {folder_path}: Not a valid directory")
                continue
            
            for filename in os.listdir(folder_path):
                if filename.endswith('.xml'):
                    file_path = os.path.join(folder_path, filename)
                    
                    try:
                        with open(file_path, 'r', encoding='utf-8') as file:
                            soup = BeautifulSoup(file, 'html.parser')
                            abstract = soup.find('abstract')
                            
                            if abstract:
                                abstract_path = os.path.join(folder_path, "html_bodies")
                                if not os.path.exists(abstract_path):
                                    os.makedirs(abstract_path)
                                    
                                output_file_path = os.path.join(abstract_path, f"{os.path.splitext(filename)[0]}_abstract.html")
                                with open(output_file_path, 'w', encoding='utf-8') as output_file:
                                    output_file.write(str(abstract))
                                    
                                abstract_contents[file_path] = str(abstract)
                            else:
                                print(f"No abstract tag found in file: {file_path}")
                                
                    except Exception as e:
                        print(f"Error processing file {file_path}: {e}")
                        
        return abstract_contents